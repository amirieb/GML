<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Syllabus and Textbooks</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">COMP5800</div>
<div class="menu-item"><a href=".">Home</a></div>
<div class="menu-item"><a href="syllabus.html" class="current">Syllabus</a></div>
<div class="menu-item"><a href="grading.html">Grading</a></div>
<div class="menu-item"><a href="policies.html">Policies</a></div>
<div class="menu-item"><a href="resources.html">Resources</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Syllabus and Textbooks</h1>
</div>
<p>The required reading will be mainly from select conference/journal articles (listed below for each lecture), which are all available online, as well as a few chapters of the following textbook:</p>
<ul>
<li><p>[<b>GRL</b>] <a target='_new' href="https://www.cs.mcgill.ca/~wlh/grl_book/">Graph Representation Learning</a><br />
William L. Hamilton</p>
</li>
</ul>
<h2>Syllabus </h2>
<p>Prior to every class, we provide a list of papers - select research papers relevant to a specific lecture. Students are encouraged to read these papers before the class. See further details in Policies section. GRL indicates the above text. Slides, lecture ntoes and other materials will be available on <a target='_new' href="https://uml.umassonline.net/">Blackboard</a>.</p>
<p><b> Week 1: Introduction and Basics</b> </p>
<ul>
<li><p>Ch.01 Introduction [GRL]</p>
</li>
<li><p>Ch.22 Elementary Graph Algorithms [CLRS]</p>
</li>
<li><p>Ch.24 Single Source Shortest Paths [CLRS]</p>
</li>
</ul>
<p><b> Week 2: Graph Properties and Features I</b></p>
<ul>
<li><p>Ch.02 Background and Traditional Approaches  [GRL] </p>
</li>
<li><p>Global connectivity and multilinguals in the Twitter network. Hale, S.A. SIGCHI&rsquo;14</p>
</li>
<li><p>Searching for superspreaders of information in real-world social media. Pei, S., et al. Scientific reports&rsquo;14.</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 1 (out), Project Proposal (out)</p>
</li>
</ul>
<p><b> Week 3: Graph Properties and Features II</b></p>
<ul>
<li><p>Ch.02 Background and Traditional Approaches  [GRL] </p>
</li>
<li><p>Graph structure in the web. Broder, A., et al. Computer networks&rsquo;00.</p>
</li>
<li><p>Structure and tie strengths in mobile communication networks. Onnela, J.P., et al. PNAS&rsquo;07.</p>
</li>
</ul>
<p><b> Week 4: Node Embedding I</b></p>
<ul>
<li><p>Distributed representations of words and phrases and their compositionality. Mikolov, T., et al. NIPS&rsquo;13.</p>
</li>
<li><p>Glove: global vectors for word representation. Pennington, J., et al. EMNLP&rsquo;14. </p>
</li>
<li><p>Evaluation methods for unsupervised word embeddings. Schnabel, T., et al. EMNLP&rsquo;15.</p>
</li>
<li><p><img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: Distributional semantics. 
</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 1 (in), Assignment 2 (out)</p>
</li>
</ul>
<p><b> Week 5: Node Embedding II </b></p>
<ul>
<li><p>Ch.03 Neighborhood Reconstruction Method [GRL] </p>
</li>
<li><p>Node2vec: scalable feature learning for networks. Grover, A. and Leskovec, J. SIGKDD&rsquo;16.</p>
</li>
<li><p>Deepwalk: online learning of social representations. Perozzi, B., et al. SIGKDD&rsquo;14.</p>
</li>
<li><p><a target='_new' href="https://youtu.be/YrhBZUtgG4E"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> Course Lecture: <a target='_new' href="https://youtu.be/YrhBZUtgG4E">Graph Representation Learning</a>. Leskovec J. 2019. </p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 2 (in), Assignment 3 (out)</p>
</li>
</ul>
<p><b> Week 6: Node Embedding III</b></p>
<ul>
<li><p>Retrofitting word vectors to semantic lexicons. Faruqui, M., et al. NAACL&rsquo;15.</p>
</li>
<li><p><a target='_new' href="https://www.youtube.com/watch?v=yG4XbgytH4w"><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"></a> AI2 talk: <a target='_new' href="https://www.youtube.com/watch?v=yG4XbgytH4w">Beyond the Distributional Hypothesis: Learning Better Word Representations</a>. Manaal F. 2016. </p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 3 (in)</p>
</li>
</ul>
<p><b> Week 7: Exam</b>  </p>
<ul>
<li><p>Midterm exam <br /></p>
</li>
<li><p>See details on <a target='_new' href="https://uml.umassonline.net/">Blackboard</a>.</p>
</li>
</ul>
<p><b> Week 8: Graph Neural Networks I</b></p>
<ul>
<li><p>Ch.05 The Graph Neural Network Model [GRL]</p>
</li>
<li><p>Random walk graph neural networks. Giannis, N. et al. NeurIPS&rsquo;20</p>
</li>
<li><p>Inductive representation learning on large graphs. Hamilton, W., et al. NIPS&rsquo;17.</p>
</li>
<li><p>Semi-supervised classification with graph convolutional networks. Kipf, T.N., et al. ICLR&rsquo;17.</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 4 (out)</p>
</li>
</ul>
<p><b> Week 9: Projects</b> 	 </p>
<ul>
<li><p>Proposal presentations <br /></p>
</li>
<li><p>See details on <a target='_new' href="https://uml.umassonline.net/">Blackboard</a>.</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Project Proposal (in), Project Report (out).</p>
</li>
</ul>
<p><b> Week 10: Graph Neural Networks II</b></p>
<ul>
<li><p>Strategies for pre-training graph neural networks. Hu, Weihua, et al. ICLR&rsquo;20.</p>
</li>
<li><p>Learning convolutional neural networks for graphs. Niepert, M., et al. ICML&rsquo;16.</p>
</li>
<li><p>Assignment 5 (out)</p>
</li>
</ul>
<p><b> Week 11: Graph Neural Networks III</b></p>
<ul>
<li><p>Graph convolutional neural networks for web-scale recommender systems. Ying, R., et al. KDD&rsquo;18.</p>
</li>
<li><p><img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: GraphSAGE.</p>
</li>
<li><p><img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: StellarGraph.
</p>
</li>
</ul>
<p><b> Week 12: Meta Learning with Graphs I </b></p>
<ul>
<li><p>Neural self-training through spaced repetition. Amiri H. NAACL&rsquo;19.</p>
</li>
<li><p>Mentornet: Learning data-driven curriculum for very DNNs on corrupted labels. Lu, J., et al. ICML&rsquo;18.</p>
</li>
<li><p>Spaced repetition for efficient and effective training of neural networks. Amiri H., et al. EMNLP&rsquo;17.</p>
</li>
<li><p>Self-paced curriculum learning. Lu, J., et al. AAAI&rsquo;15.</p>
</li>
<li><p>Curriculum learning. Yoshua, B. et al. ICML&rsquo;09.</p>
</li>
<li><p><img src="files/t.png" alt="tutorial" width="20px" style="vertical-align: -4px; padding-right: 2px"> Tutorial: Leitner system.
</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 4 (in)</p>
</li>
</ul>
<p><b> Week 13: Thanksgiving Recess</b></p>
<ul>
<li><p>no class.</p>
</li>
</ul>
<p><b> Week 14: Meta Learning with Graphs II </b></p>
<ul>
<li><p>CurGraph: curriculum learning for graph classification. Wang, Yiwei, et al. WWW&rsquo;21.</p>
</li>
<li><p>Curriculum learning by dynamic instance hardness. Zhou, T., et al. NeurIPS&rsquo;20.  </p>
</li>
<li><p>SuperLoss: a generic loss for robust curriculum learning. Castells, et al. NeurIPS&rsquo;20.</p>
</li>
<li><p>Multi-Modal curriculum learning over graphs. Chen, G., et al. TIST&rsquo;19</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Assignment 5 (in)</p>
</li>
</ul>
<p><b> Week 15: Projects</b> 	</p>
<ul>
<li><p>Final project presentations. </p>
</li>
<li><p>See details on <a target='_new' href="https://uml.umassonline.net/">Blackboard</a>.</p>
</li>
<li><p><img src="files/clip.jpeg" alt="video lecture or talk" width="20px" style="vertical-align: -4px; padding-right: 2px"> Project Report (in).</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2022-01-24 00:13:20 EST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
